### Web Crawler

This is a guided project from [Boot.dev](https://www.boot.dev/courses/build-web-crawler-golang)

##### TODOs

- [ ] Make the script run on a timer and deploy it to a server. Have it email you every so often with a report.
- [ ] Add more robust error checking so that you can crawl larger sites without issues.
- [x] Count external links, as well as internal links, and add them to the report
- [x] Save the report as a CSV spreadsheet rather than printing it to the console
- [ ] Use a graphics library to create an image that shows the links between the pages as a graph visualization
- [ ] Make requests concurrently to speed up the crawling process
- [ ] Add a README.md file explaining to users how to clone your git repo and get started
